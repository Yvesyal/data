# 设计一个百万级的消息推送系统

![business-communication-computer-261706.jpg](https://i.loli.net/2018/09/23/5ba7ae180e8eb.jpg)



# 技术选型

要满足大量的连接数、同时支持双全工通信，并且性能也得有保障。

在 Java 技术栈中进行选型首先自然是排除掉了传统 `IO`。

那就只有选 NIO 了，在这个层面其实选择也不多，考虑到社区、资料维护等方面最终选择了 Netty。

最终的架构图如下：

![](https://i.loli.net/2019/07/19/5d313936e89ff75333.jpg)

现在看着蒙没关系，下文一一介绍。

# 协议解析

既然是一个消息系统，那自然得和客户端定义好双方的协议格式。

常见和简单的是 HTTP 协议，但我们的需求中有一项需要是双全工的交互方式，同时 HTTP 更多的是服务于浏览器。我们需要的是一个更加精简的协议，减少许多不必要的数据传输。

因此我觉得最好是在满足业务需求的情况下定制自己的私有协议，在我这个场景下其实有标准的物联网协议。

如果是其他场景可以借鉴现在流行的 `RPC` 框架定制私有协议，使得双方通信更加高效。

不过根据这段时间的经验来看，不管是哪种方式都得在协议中预留安全相关的位置。

协议相关的内容就不过讨论了，更多介绍具体的应用。

# 简单实现

首先考虑如何实现功能，再来思考百万连接的情况。

## 注册鉴权

在做真正的消息上、下行之前首先要考虑的就是鉴权问题。

就像你使用微信一样，第一步怎么也得是登录吧，不能无论是谁都可以直接连接到平台。

所以第一步得是注册才行。

如上面架构图中的 `注册/鉴权` 模块。通常来说都需要客户端通过 `HTTP` 请求传递一个唯一标识，后台鉴权通过之后会响应一个 `token`，并将这个 `token` 和客户端的关系维护到 `Redis` 或者是 DB 中。

客户端将这个 token 也保存到本地，今后的每一次请求都得带上这个 token。一旦这个 token 过期，客户端需要再次请求获取 token。

鉴权通过之后客户端会直接通过`TCP 长连接`到图中的 `push-server` 模块。

这个模块就是真正处理消息的上、下行。

## 保存通道关系

在连接接入之后，真正处理业务之前需要将当前的客户端和 Channel 的关系维护起来。

假设客户端的唯一标识是手机号码，那就需要把手机号码和当前的 Channel 维护到一个 Map 中。


同时为了可以通过 Channel 获取到客户端唯一标识（手机号码），还需要在 Channel 中设置对应的属性：

```
public static void putClientId(Channel channel, String clientId) {
    channel.attr(CLIENT_ID).set(clientId);
}
```

获取时手机号码时：

```
public static String getClientId(Channel channel) {
    return (String)getAttribute(channel, CLIENT_ID);
}
```

这样当我们客户端下线的时便可以记录相关日志：

```
String telNo = NettyAttrUtil.getClientId(ctx.channel());
NettySocketHolder.remove(telNo);
log.info("客户端下线，TelNo=" +  telNo);
```

> 这里有一点需要注意：存放客户端与 Channel 关系的 Map 最好是预设好大小（避免经常扩容），因为它将是使用最为频繁同时也是占用内存最大的一个对象。

## 消息上行

接下来则是真正的业务数据上传，通常来说第一步是需要判断上传消息输入什么业务类型。

在聊天场景中，有可能上传的是文本、图片、视频等内容。

所以我们得进行区分，来做不同的处理；这就和客户端协商的协议有关了。

- 可以利用消息头中的某个字段进行区分。
- 更简单的就是一个 `JSON` 消息，拿出一个字段用于区分不同消息。

不管是哪种只有可以区分出来即可。

### 消息解析与业务解耦

消息可以解析之后便是处理业务，比如可以是写入数据库、调用其他接口等。

我们都知道在 Netty 中处理消息一般是在 `channelRead()` 方法中。

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fvkkawymbkj30o6027mxf.jpg)

在这里可以解析消息，区分类型。

但如果我们的业务逻辑也写在里面，那这里的内容将是巨多无比。

甚至我们分为好几个开发来处理不同的业务，这样将会出现许多冲突、难以维护等问题。

所以非常有必要将消息解析与业务处理完全分离开来。


> 这时面向接口编程就发挥作用了。


都是先定义一个接口用于处理业务逻辑，然后在解析消息之后通过反射创建具体的对象执行其中的`处理函数`即可。

这样不同的业务、不同的开发人员只需要实现这个接口同时实现自己的业务逻辑即可。



上行还有一点需要注意；由于是基于长连接，所以客户端需要定期发送心跳包用于维护本次连接。同时服务端也会有相应的检查，N 个时间间隔没有收到消息之后将会主动断开连接节省资源。

这点使用一个 `IdleStateHandler` 就可实现，



## 消息下行

有了上行自然也有下行。比如在聊天的场景中，有两个客户端连上了 `push-server`,他们直接需要点对点通信。

这时的流程是：

- A 将消息发送给服务器。
- 服务器收到消息之后，得知消息是要发送给 B，需要在内存中找到 B 的 Channel。
- 通过 B 的 Channel 将 A 的消息转发下去。

这就是一个下行的流程。

甚至管理员需要给所有在线用户发送系统通知也是类似：

遍历保存通道关系的 Map，挨个发送消息即可。这也是之前需要存放到 Map 中的主要原因。




# 分布式方案

单机版的实现了，现在着重讲讲如何实现百万连接。

百万连接其实只是一个形容词，更多的是想表达如何来实现一个分布式的方案，可以灵活的水平拓展从而能支持更多的连接。

再做这个事前首先得搞清楚我们单机版的能支持多少连接。影响这个的因素就比较多了。

- 服务器自身配置。内存、CPU、网卡、Linux 支持的最大文件打开数等。
- 应用自身配置，因为 Netty 本身需要依赖于堆外内存，但是 JVM 本身也是需要占用一部分内存的，比如存放通道关系的大 `Map`。这点需要结合自身情况进行调整。

结合以上的情况可以测试出单个节点能支持的最大连接数。

单机无论怎么优化都是有上限的，这也是分布式主要解决的问题。

## 架构介绍


上文提到的 `注册鉴权` 模块也是集群部署的，通过前置的 Nginx 进行负载。之前也提过了它主要的目的是来做鉴权并返回一个 token 给客户端。

但是 `push-server` 集群之后它又多了一个作用。那就是得返回一台可供当前客户端使用的 `push-server`。

右侧的 `平台` 一般指管理平台，它可以查看当前的实时在线数、给指定客户端推送消息等。

推送消息则需要经过一个推送路由（`push-server`）找到真正的推送节点。

其余的中间件如：Redis、Zookeeper、Kafka、MySQL 都是为了这些功能所准备的，具体看下面的实现。

## 注册发现

首先第一个问题则是 `注册发现`，`push-server` 变为多台之后如何给客户端选择一台可用的节点是第一个需要解决的。

所有的 `push-server` 在启动时候需要将自身的信息注册到 Zookeeper 中。

`注册鉴权` 模块会订阅 Zookeeper 中的节点，从而可以获取最新的服务列表。

应用启动注册 Zookeeper。

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fvkriuz7yrj30m304lq3r.jpg)

![](https://ws4.sinaimg.cn/large/006tNbRwgy1fvkrj927rsj30od08ejst.jpg)

对于`注册鉴权`模块来说只需要订阅这个 Zookeeper 节点：

![](https://ws2.sinaimg.cn/large/006tNbRwgy1fvkrlfdgrkj30tb08j0uf.jpg)

### 路由策略

既然能获取到所有的服务列表，那如何选择一台刚好合适的 `push-server` 给客户端使用呢？

这个过程重点要考虑以下几点：

- 尽量保证各个节点的连接均匀。
- 增删节点是否要做 Rebalance。

首先保证均衡有以下几种算法：

- 轮询。挨个将各个节点分配给客户端。但会出现新增节点分配不均匀的情况。
- Hash 取模的方式。类似于 HashMap，但也会出现轮询的问题。当然也可以像 HashMap 那样做一次 Rebalance，让所有的客户端重新连接。不过这样会导致所有的连接出现中断重连，代价有点大。
- 由于 Hash 取模方式的问题带来了一致性 Hash`算法，但依然会有一部分的客户端需要 Rebalance。
- 权重。可以手动调整各个节点的负载情况，甚至可以做成自动的，基于监控当某些节点负载较高就自动调低权重，负载较低的可以提高权重。

还有一个问题是：

> 当我们在重启部分应用进行升级时，在该节点上的客户端怎么处理？

由于我们有心跳机制，当心跳不通之后就可以认为该节点出现问题了。那就得重新请求`注册鉴权`模块获取一个可用的节点。在弱网情况下同样适用。

如果这时客户端正在发送消息，则需要将消息保存到本地等待获取到新的节点之后再次发送。

## 有状态连接

在这样的场景中不像是 HTTP 那样是无状态的，我们得明确的知道各个客户端和连接的关系。

在上文的单机版中我们将这个关系保存到本地的缓存中，但在分布式环境中显然行不通了。

比如在平台向客户端推送消息的时候，它得首先知道这个客户端的通道保存在哪台节点上。

借助我们以前的经验，这样的问题自然得引入一个第三方中间件用来存放这个关系。

也就是架构图中的存放`路由关系的 Redis`，在客户端接入 `push-server` 时需要将当前客户端唯一标识和服务节点的 `ip+port` 存进 `Redis`。

同时在客户端下线时候得在 Redis 中删掉这个连接关系。


> 这样在理想情况下各个节点内存中的 map 关系加起来应该正好等于 Redis 中的数据。

伪代码如下：

![](https://ws1.sinaimg.cn/large/006tNbRwgy1fvkt2ytdxoj30r109u40n.jpg)

这里存放路由关系的时候会有并发问题，最好是换为一个 `lua` 脚本。

## 推送路由

设想这样一个场景：管理员需要给最近注册的客户端推送一个系统消息会怎么做？

> 结合架构图

假设这批客户端有 10W 个，首先我们需要将这批号码通过`平台`下的 `Nginx` 下发到一个推送路由中。

为了提高效率甚至可以将这批号码再次分散到每个 `push-route` 中。

拿到具体号码之后再根据号码的数量启动多线程的方式去之前的路由 Redis 中获取客户端所对应的 `push-server`。

再通过 HTTP 的方式调用 `push-server` 进行真正的消息下发（Netty 也很好的支持 HTTP 协议）。

推送成功之后需要将结果更新到数据库中，不在线的客户端可以根据业务再次推送等。

## 消息流转

也许有些场景对于客户端上行的消息非常看重，需要做持久化，并且消息量非常大。

在 `push-sever` 做业务显然不合适，这时完全可以选择 Kafka 来解耦。

将所有上行的数据直接往 Kafka 里丢后就不管了。

再由消费程序将数据取出写入数据库中即可。

其实这块内容也很值得讨论，可以先看这篇了解下：强如 Disruptor 也发生内存溢出？

后续谈到 Kafka 再做详细介绍。

# 分布式问题

分布式解决了性能问题但却带来了其他麻烦。

## 应用监控

比如如何知道线上几十个 `push-server` 节点的健康状况？

这时就得监控系统发挥作用了，我们需要知道各个节点当前的内存使用情况、GC。

以及操作系统本身的内存使用，毕竟 Netty 大量使用了堆外内存。

同时需要监控各个节点当前的在线数，以及 Redis 中的在线数。理论上这两个数应该是相等的。

这样也可以知道系统的使用情况，可以灵活的维护这些节点数量。

## 日志处理

日志记录也变得异常重要了，比如哪天反馈有个客户端一直连不上，你得知道问题出在哪里。


最好是给每次请求都加上一个 traceID 记录日志，这样就可以通过这个日志在各个节点中查看到底是卡在了哪里。

以及 ELK 这些工具都得用起来才行。



# 架构设计

下面来看看具体的架构设计。

![](https://i.loli.net/2019/07/19/5d313936e89ff75333.jpg)

- `CIM` 中的各个组件均采用 `SpringBoot` 构建。
-  采用 `Netty + Google Protocol Buffer` 构建底层通信。
-  `Redis` 存放各个客户端的路由信息、账号信息、在线状态等。
-  `Zookeeper` 用于 `IM-server` 服务的注册与发现。

整体主要由以下模块组成：

## cim-server

`IM` 服务端；用于接收 `client` 连接、消息透传、消息推送等功能。

**支持集群部署。**

## cim-forward-route

消息路由服务器；用于处理消息路由、消息转发、用户登录、用户下线以及一些运营工具（获取在线用户数等）。

## cim-client

`IM` 客户端；给用户使用的消息终端，一个命令即可启动并向其他人发起通讯（群聊、私聊）；同时内置了一些常用命令方便使用。


# 流程图

整体的流程也比较简单，流程图如下：

![](https://i.loli.net/2019/07/19/5d31393783d9878382.jpg)

- 客户端向 `route` 发起登录。
- 登录成功从 `Zookeeper` 中选择可用 `IM-server` 返回给客户端，并保存登录、路由信息到 `Redis`。
- 客户端向 `IM-server` 发起长连接，成功后保持心跳。
- 客户端下线时通过 `route` 清除状态信息。


所以当我们自己部署时需要以下步骤：

- 搭建基础中间件 `Redis、Zookeeper`。
- 部署 `cim-server`，这是真正的 IM 服务器，为了满足性能需求所以支持水平扩展，只需要注册到同一个 `Zookeeper` 即可。
- 部署 `cim-forward-route`，这是路由服务器，所有的消息都需要经过它。由于它是无状态的，所以也可以利用 `Nginx` 代理提高可用性。
- `cim-client` 真正面向用户的客户端；启动之后会自动连接 IM 服务器便可以在控制台收发消息了。


# 详细设计

接下来重点看看具体的实现，比如群聊、私聊消息如何流转；IM 服务端负载均衡；服务如何注册发现等等。

## IM 服务端

先来看看服务端；主要是实现客户端上下线、消息下发等功能。

首先是服务启动：

![](https://i.loli.net/2019/07/19/5d31393808e5864405.jpg)
![](https://i.loli.net/2019/07/19/5d313938780ae12933.jpg)

由于是在 `SpringBoot` 中搭建的，所以在应用启动时需要启动 `Netty` 服务。

从 `pipline` 中可以看出使用了 `Protobuf` 的编解码（具体报文在客户端中分析）。

## 注册发现

需要满足 `IM` 服务端的水平扩展需求，所以 `cim-server` 是需要将自身数据发布到注册中心的。


所以在应用启动成功后需要将自身数据注册到 `Zookeeper` 中。

![](https://i.loli.net/2019/07/19/5d313938d33fb47365.jpg)
![](https://i.loli.net/2019/07/19/5d31393ec08cc70862.jpg)

最主要的目的就是将当前应用的 `ip + cim-server-port+ http-port` 注册上去。


![](https://i.loli.net/2019/07/19/5d3139401722563891.jpg)

上图是我在演示环境中注册的两个 `cim-server` 实例（由于在一台服务器，所以只是端口不同）。

这样在客户端（监听这个 `Zookeeper` 节点）就能实时的知道目前可用的服务信息。

## 登录

当客户端请求 `cim-forward-route` 中的登录接口（详见下文）做完业务验证（就相当于日常登录其他网站一样）之后，客户端会向服务端发起一个长连接，如之前的流程所示：

![](https://i.loli.net/2019/07/19/5d313940c94a652003.jpg)

这时客户端会发送一个特殊报文，表明当前是登录信息。

服务端收到后就需要将该客户端的 `userID` 和当前 `Channel` 通道关系保存起来。

![](https://i.loli.net/2019/07/19/5d3139429a08032119.jpg)
![](https://i.loli.net/2019/07/19/5d313943a25c029466.jpg)

同时也缓存了用户的信息，也就是 `userID` 和 用户名。


## 离线

当客户端断线后也需要将刚才缓存的信息清除掉。

![](https://i.loli.net/2019/07/19/5d313944af8c328873.jpg)

同时也需要调用 `route` 接口清除相关信息（具体接口看下文）。



## IM 路由

![](https://i.loli.net/2019/07/19/5d313945a039126377.jpg)

从架构图中可以看出，路由层是非常重要的一环；它提供了一系列的 `HTTP` 服务承接了客户端和服务端。

目前主要是以下几个接口。

### 注册接口

![](https://i.loli.net/2019/07/19/5d313946d089382853.jpg)
![](https://i.loli.net/2019/07/19/5d31394c795cc10022.jpg)

由于每一个客户端都是需要登录才能使用的，所以第一步自然是注册。

这里就设计的比较简单，直接利用 `Redis` 来存储用户信息；用户信息也只有 `ID` 和 `userName` 而已。

只是为了方便查询在 `Redis` 中的 `KV` 又反过来存储了一份 `VK`，这样 `ID` 和 `userName` 都必须唯一。


### 登录接口

这里的登录和 `cim-server` 中的登录不一样，具有业务性质，

![](https://i.loli.net/2019/07/19/5d31394d5915e56923.jpg)

- 登录成功之后需要判断是否是重复登录（一个用户只能运行一个客户端）。
- 登录成功后需要从 `Zookeeper` 中获取服务列表（`cim-server`）并根据某种算法选择一台服务返回给客户端。
- 登录成功之后还需要保存路由信息，也就是当前用户分配的服务实例保存到 `Redis` 中。

为了实现只能一个用户登录，使用了 `Redis` 中的 `set` 来保存登录信息；利用 `userID` 作为 `key` ，重复的登录就会写入失败。

![](https://i.loli.net/2019/07/19/5d31394de19fe32033.jpg)
![](https://i.loli.net/2019/07/19/5d31394e5a7cf72944.jpg)

> 类似于 Java 中的 HashSet，只能去重保存。


获取一台可用的路由实例也比较简单：

![](https://i.loli.net/2019/07/19/5d31394ed00d392001.jpg)

- 先从 `Zookeeper` 获取所有的服务实例做一个内部缓存。
- 轮询选择一台服务器（目前只有这一种算法，后续会新增）。

当然要获取 `Zookeeper` 中的服务实例前自然是需要监听 `cim-server` 之前注册上去的那个节点。

具体代码如下：

![](https://i.loli.net/2019/07/19/5d31394f4609531937.jpg)
![](https://i.loli.net/2019/07/19/5d31394f9ad3c50783.jpg)
![](https://i.loli.net/2019/07/19/5d31395006b0b64086.jpg)

也是在应用启动之后监听 `Zookeeper` 中的路由节点，一旦发生变化就会更新内部缓存。

> 这里使用的是 Guava 的 cache，它基于 `ConcurrentHashMap`，所以可以保证`清除、新增缓存`的原子性。

### 群聊接口

这是一个真正发消息的接口，实现的效果就是其中一个客户端发消息，其余所有客户端都能收到！

流程肯定是客户端发送一条消息到服务端，服务端收到后在上文介绍的 `SessionSocketHolder` 中遍历所有 `Channel`（通道）然后下发消息即可。

服务端是单机倒也可以，但现在是集群设计。所以所有的客户端会根据之前的轮询算法分配到不同的 `cim-server` 实例中。

因此就需要路由层来发挥作用了。

![](https://i.loli.net/2019/07/19/5d313955b870762733.jpg)
![](https://i.loli.net/2019/07/19/5d31395784bf477598.jpg)

路由接口收到消息后首先遍历出所有的客户端和服务实例的关系。

路由关系在 `Redis` 中的存放如下：

![](https://i.loli.net/2019/07/19/5d313957c158a14876.jpg)

由于 `Redis` 单线程的特质，当数据量大时；一旦使用 keys 匹配所有 `cim-route:*` 数据，会导致 Redis 不能处理其他请求。

所以这里改为使用 scan 命令来遍历所有的 `cim-route:*`。

---

接着会挨个调用每个客户端所在的服务端的 `HTTP` 接口用于推送消息。

在 `cim-server` 中的实现如下：

![](https://i.loli.net/2019/07/19/5d3139590e61247525.jpg)
![](https://i.loli.net/2019/07/19/5d31395979de822216.jpg)

`cim-server` 收到消息后会在内部缓存中查询该 userID 的通道，接着只需要发消息即可。


### 在线用户接口

这是一个辅助接口，可以查询出当前在线用户信息。

![](https://i.loli.net/2019/07/19/5d313959c343668519.jpg)
![](https://i.loli.net/2019/07/19/5d31395a06ae762846.jpg)

实现也很简单，也就是查询之前保存 ”用户登录状态的那个去重 `set` “即可。

### 私聊接口

之所以说获取在线用户是一个辅助接口，其实就是用于辅助私聊使用的。

一般我们使用私聊的前提肯定得知道当前哪些用户在线，接着你才会知道你要和谁进行私聊。

类似于这样：

![](https://i.loli.net/2019/07/19/5d31396246da062612.jpg)

在我们这个场景中，私聊的前提就是需要获得在线用户的 `userID`。


![](https://i.loli.net/2019/07/19/5d3139637537e14521.jpg)

所以私聊接口在收到消息后需要查询到接收者所在的 `cim-server` 实例信息，后续的步骤就和群聊一致了。调用接收者所在实例的 `HTTP` 接口下发信息。

只是群聊是遍历所有的在线用户，私聊只发送一个的区别。

### 下线接口

一旦客户端下线，我们就需要将之前存放在 `Redis` 中的一些信息删除掉（路由信息、登录状态）。

![](https://i.loli.net/2019/07/19/5d313963e388b20088.jpg)
![](https://i.loli.net/2019/07/19/5d3139642e6b729312.jpg)




## IM 客户端

客户端中的一些逻辑其实在上文已经谈到一些了。

### 登录 

第一步也就是登录，需要在启动时调用 `route` 的登录接口，获得 `cim-server` 信息再创建连接。

![](https://i.loli.net/2019/07/19/5d3139645e63671036.jpg)

![image-20190102001525565](https://i.loli.net/2019/07/19/5d313964a2d2194790.jpg)

![](https://i.loli.net/2019/07/19/5d3139661c62598094.jpg)

登录过程中 `route` 接口会判断是否为重复登录，重复登录则会直接退出程序。

![](https://i.loli.net/2019/07/19/5d31396b6301828962.jpg)

接下来是利用 `route` 接口返回的 `cim-server` 实例信息（`ip+port`）创建连接。

最后一步就是发送一个登录标志的信息到服务端，让它保持客户端和 `Channel` 的关系。

![](https://i.loli.net/2019/07/19/5d31396ba9bfa44516.jpg)

### 自定义协议

上文提到的一些`登录报文、真正的消息报文`这些其实都是在我们自定义协议中可以区别出来的。

由于是使用 `Google Protocol Buffer` 编解码，所以先看看原始格式。

![](https://i.loli.net/2019/07/19/5d31396be687915596.jpg)

其实这个协议中目前一共就三个字段：

- `requestId` 可以理解为 `userId`。
- `reqMsg` 就是真正的消息。
- `type` 也就是上文提到的消息类别。


目前主要是三种类型，分别对应不同的业务：

![](https://i.loli.net/2019/07/19/5d313aac604fa88452.jpg)

### 心跳

为了保持客户端和服务端的连接，每隔一段时间没有发送消息都需要自动的发送心跳。

目前的策略是每隔一分钟就是发送一个心跳包到服务端：

![](https://i.loli.net/2019/07/19/5d313aad7641038034.jpg)
![](https://i.loli.net/2019/07/19/5d313aae3e8ee56138.jpg)

这样服务端每隔一分钟没有收到业务消息时就会收到 `ping` 的心跳包：

![](https://i.loli.net/2019/07/19/5d313aaed8e5685298.jpg)


### 内置命令

客户端也内置了一些基本命令来方便使用。

| 命令 | 描述|
| ------ | ------ |
| `:q` | 退出客户端|
| `:olu` | 获取所有在线用户信息 |
| `:all` | 获取所有命令 |
| `:` | 更多命令正在开发中。。 |

![](https://i.loli.net/2019/07/19/5d31396246da062612.jpg)

比如输入 `:q` 就会退出客户端，同时会关闭一些系统资源。

![](https://i.loli.net/2019/07/19/5d313aaf6f05466906.jpg)
![](https://i.loli.net/2019/07/19/5d313aafe852815113.jpg)

当输入 `:olu`(`onlineUser` 的简写)就会去调用 `route` 的获取所有在线用户接口。

![](https://i.loli.net/2019/07/19/5d313ab06dd6c35435.jpg)
![](https://i.loli.net/2019/07/19/5d313ab0ea75d16268.jpg)

### 群聊

群聊的使用非常简单，只需要在控制台输入消息回车即可。

这时会去调用 `route` 的群聊接口。

![](https://i.loli.net/2019/07/19/5d313ab63223a26868.jpg)

### 私聊

私聊也是同理，但前提是需要触发关键字；使用 `userId;;消息内容` 这样的格式才会给某个用户发送消息，所以一般都需要先使用 `:olu` 命令获取所以在线用户才方便使用。

![](https://i.loli.net/2019/07/19/5d313ab6ac1d016245.jpg)

### 消息回调

为了满足一些定制需求，比如消息需要保存之类的。

所以在客户端收到消息之后会回调一个接口，在这个接口中可以自定义实现。

![](https://i.loli.net/2019/07/19/5d313ab75333232387.jpg)
![](https://i.loli.net/2019/07/19/5d313ab7e6e3426627.jpg)

因此先创建了一个 `caller` 的 `bean`，这个 `bean` 中包含了一个 `CustomMsgHandleListener` 接口，需要自行处理只需要实现此接口即可。

### 自定义界面

由于我自己不怎么会写界面，但保不准有其他大牛会写。所以客户端中的群聊、私聊、获取在线用户、消息回调等业务(以及之后的业务)都是以接口形式提供。

也方便后面做页面集成，只需要调这些接口就行了；具体实现不用怎么关心。



# 其他
喜欢的同学点个星星，打赏奖励一下博主！！！

 <img src="https://img-blog.csdnimg.cn/20210414173956371.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tlMzY5MDkzNDU3,size_16,color_FFFFFF,t_70" width = "200" height = "250" alt="图片名称" align=center />
 <img src="https://img-blog.csdnimg.cn/20210414174007800.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tlMzY5MDkzNDU3,size_16,color_FFFFFF,t_70" width = "200" height = "250" alt="图片名称" align=center />
 
